---
title: "Customized Mid-Air Gestures for Accessibility: A $B Recognizer for Multi-Dimensional Biosignal Gestures"
collection: publications
category: journal_conference
permalink: /publication/dollar_B
excerpt: 'An algorithm for gesture personalization for wearable signals based on the $1 recognizer.'
date: 2024-09-12
venue: 'arXiv'
slidesurl: #'https://academicpages.github.io/files/slides1.pdf'
paperurl: #'https://academicpages.github.io/files/paper1.pdf'
bibtexurl: #'https://academicpages.github.io/files/bibtex1.bib'
citation: 'Momona Yamagami, Claire L. Mitchell, Alexandra A. Portnova-Fahreeva, Junhan Kong, Jennifer Mankoff, Jacob O. Wobbrock. &quot; Customized Mid-Air Gestures for Accessibility: A $B Recognizer for Multi-Dimensional Biosignal Gestures.&quot; <a href="https://arxiv.org/abs/2409.08402">https://arxiv.org/abs/2409.08402</a>'
---
Biosignal interfaces, using sensors in, on, or around the body, promise to enhance wearables interaction and improve device accessibility for people with motor disabilities. However, biosignals are multi-modal, multi-dimensional, and noisy, requiring domain expertise to design input features for gesture classifiers. The $B-recognizer enables mid-air gesture recognition without needing expertise in biosignals or algorithms. $B resamples, normalizes, and performs dimensionality reduction to reduce noise and enhance signals relevant to the recognition. We tested $B on a dataset of 26 participants with and 8 participants without upper-body motor disabilities performing personalized ability-based gestures. For two conditions (user-dependent, gesture articulation variability), $B outperformed our comparison algorithms (traditional machine learning with expert features and deep learning), with > 95% recognition rate. For the user-independent condition, $B and deep learning performed comparably for participants with disabilities. Our biosignal dataset is publicly available online. $B highlights the potential and feasibility of accessible biosignal interfaces.
